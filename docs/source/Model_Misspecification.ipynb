{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2df8c31",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Model-specification\" data-toc-modified-id=\"Model-specification-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model specification</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-loop\" data-toc-modified-id=\"Training-loop-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Training loop</a></span></li><li><span><a href=\"#Diagnostics\" data-toc-modified-id=\"Diagnostics-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Diagnostics</a></span></li><li><span><a href=\"#Inspecting-the-summary-space\" data-toc-modified-id=\"Inspecting-the-summary-space-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Inspecting the summary space</a></span></li></ul></li><li><span><a href=\"#Observed-Data:-Misspecification-Detection\" data-toc-modified-id=\"Observed-Data:-Misspecification-Detection-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Observed Data: Misspecification Detection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Visualization-in-data-space\" data-toc-modified-id=\"Visualization-in-data-space-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Visualization in data space</a></span></li><li><span><a href=\"#Detecting-misspecification-in-summary-space\" data-toc-modified-id=\"Detecting-misspecification-in-summary-space-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Detecting misspecification in summary space</a></span></li></ul></li><li><span><a href=\"#Hypothesis-test-for-observed-data\" data-toc-modified-id=\"Hypothesis-test-for-observed-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Hypothesis test for observed data</a></span></li><li><span><a href=\"#Sensitivity-to-Misspecification\" data-toc-modified-id=\"Sensitivity-to-Misspecification-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Sensitivity to Misspecification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Computing-Sesntivity\" data-toc-modified-id=\"Computing-Sesntivity-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Computing Sesntivity</a></span></li><li><span><a href=\"#Plotting-the-results\" data-toc-modified-id=\"Plotting-the-results-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Plotting the results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f53e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import bayesflow as bf\n",
    "from bayesflow import computational_utilities as utils\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e175999-940f-4220-8696-7ba877600f89",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34cc2c7-65d4-43b5-b71b-0515443a1abb",
   "metadata": {},
   "source": [
    "Under certain regularity conditions, the theory on simulation-based inference assures that the (amortized) neural posterior estimator $q_{\\phi}$ samples from the exact posterior $p(\\theta\\,|\\,x)$ after convergence.\n",
    "\n",
    "However, the neural posterior approximator is optimized with respect to the \"prior prredictive distribution\" of the generative model which we specify for the training process.\n",
    "When the generative model at test time (aka \"true data generating process\") deviates from the one used during training, the guarantees for the approximate neural posterior no longer hold and the approximate posterior samples can be wrong in essentially arbitrary ways.\n",
    "\n",
    "The precise definition of model misspecification in amortized inference, along with extensive implications and experiments, can be gleaned in the following pre-print: https://arxiv.org/abs/2112.08866"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c3be58",
   "metadata": {},
   "source": [
    "<img src=\"../images/model_misspecification_amortized_sbi.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab21025-c5ad-406b-a7cb-d5c59d129601",
   "metadata": {},
   "source": [
    "# Model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30c6ac",
   "metadata": {},
   "source": [
    "The general Bayesian forward model can be formulated as a two-step process:\n",
    "\n",
    "$$\n",
    "\\theta \\sim p(\\theta) \\qquad x\\sim p(x|\\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "For this showcase example, we specify a fairly simple generative model where the means of a 2-dimensional Gaussian shall be estimated: $\\theta=\\mu=(\\mu_1, \\mu_2)$. The likelihood $p(x|\\theta)$ is a Gaussian $\\mathcal{N}(\\mu, \\Sigma)$ with location $\\mu$ and covariance matrix $\\Sigma$. The prior distribution $p(\\theta)$ over the inference targets is again a Gaussian $\\mathcal{N}(\\mu_0, \\Sigma_0)$ with location $\\mu_0$ and covariance $\\Sigma_0$.\n",
    "\n",
    "Consequently, the forward model is\n",
    "\n",
    "$$\n",
    "\\mu\\sim\\mathcal{N}(\\mu_0, \\Sigma_0) \\qquad x\\sim\\mathcal{N}(\\mu, \\Sigma)\n",
    "$$\n",
    "\n",
    "with fixed parameters $\\mu_0, \\Sigma_0, \\Sigma$, and we want to perform posterior inference over the parameter vector $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de375a6",
   "metadata": {},
   "source": [
    "We choose $\\mu_0=0, \\Sigma_0=\\mathbb{I}, \\Sigma=\\mathbb{I}$ as fixed parameters of the generative model for training the neural posterior approximator. Each simulated data set contains $N=100$ observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35decbdc-2fcd-4afd-9c73-e96d7572ec53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prior(D=2, mu=0.0, sigma=1.0):\n",
    "    \"\"\"Gaussian prior random number generator.\"\"\"\n",
    "    return np.random.default_rng().normal(loc=mu, scale=sigma, size=D)\n",
    "\n",
    "\n",
    "def simulator(theta, n_obs=100, scale=1.0):\n",
    "    \"\"\"Gaussian likelihood random number generator\"\"\"\n",
    "    return np.random.default_rng().normal(loc=theta, scale=scale, size=(n_obs, theta.shape[0]))\n",
    "\n",
    "\n",
    "generative_model = bf.simulation.GenerativeModel(\n",
    "    prior=prior, simulator=simulator, name=\"Generative Model: Training\", simulator_is_batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b6c728",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f806c",
   "metadata": {},
   "source": [
    "We choose a `DeepSet` architecture [1] to learn 2 permutation-invariant summary statistics from the data, which are then passed to the posterior network and jointly optimized.\n",
    "The Inference network is a standard `InvertibleNetwork` with two coupling layers and the `AmortizedPosterior` combines the inference and summary networks. Since we desire model misspecification detection via a structured summary space [2], we select `summary_loss_fun=\"MMD\"` and the amortizer combines its losses correctly.\n",
    "Finally, the `trainer` wraps the generative model and the amortizer into a consistent object for training and subsequent sampling.\n",
    "\n",
    "[1] Zaheer et al (2017): https://arxiv.org/abs/1703.06114\n",
    "\n",
    "[2] Schmitt et al (2022): https://arxiv.org/abs/2112.08866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eff441",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = bf.networks.DeepSet(summary_dim=2)\n",
    "inference_net = bf.networks.InvertibleNetwork(num_params=2, num_coupling_layers=2)\n",
    "amortizer = bf.amortizers.AmortizedPosterior(inference_net, summary_net, summary_loss_fun=\"MMD\")\n",
    "trainer = bf.trainers.Trainer(generative_model=generative_model, amortizer=amortizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674126e",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65269680",
   "metadata": {},
   "source": [
    "Because the inference problem is simple and illustrative, we just train for 15 epochs with 500 iterations per epoch and a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fc49d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = trainer.train_online(epochs=15, iterations_per_epoch=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbbdebb",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541347e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = bf.diagnostics.plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = trainer.diagnose_sbc_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sims = trainer.configurator(trainer.generative_model(200))\n",
    "posterior_draws = amortizer.sample(new_sims, n_samples=500)\n",
    "fig = bf.diagnostics.plot_recovery(posterior_draws, new_sims[\"parameters\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3acc4",
   "metadata": {},
   "source": [
    "## Inspecting the summary space\n",
    "\n",
    "In fact, the summary space has essentially converged to a unit Gaussian for samples from the generative model which we used to train the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulations = trainer.configurator(trainer.generative_model(10000))\n",
    "summary_statistics = trainer.amortizer.summary_net(simulations[\"summary_conditions\"])\n",
    "theta = simulations[\"parameters\"]\n",
    "\n",
    "_ = bf.diagnostics.plot_latent_space_2d(summary_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf961a09-c49f-4443-b1fb-584cdc80d7c8",
   "metadata": {},
   "source": [
    "# Observed Data: Misspecification Detection\n",
    "\n",
    "After assessing the converged neural posterior approximator's performance for the reference model used for training, we will now perform inference on data from a different data generating process. In a real-life analysis, this would be the observed data $x_{\\text{obs}}$ from an experiment or study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a727c31",
   "metadata": {},
   "source": [
    "For this illustration, we choose the prior scale $\\tau_0$ as the source of misspecification. That means that we observe 1000 data sets $\\{x_{\\text{obs}}^{(k)}\\}_{k=1}^{1000}$ from a generative model with prior scale $\\tau_0=4$. Consequently, the prior covariance is $4\\cdot\\mathbb{I}=\\begin{pmatrix}4&0\\\\0&4\\end{pmatrix}$. The remaining fixed parameters $\\mu_0$ and $\\Sigma$ are unaltered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_obs(D=2, mu=0.0, sigma=4.0):\n",
    "    \"\"\"Gaussian prior random number generator.\"\"\"\n",
    "    return np.random.default_rng().normal(loc=mu, scale=sigma, size=D)\n",
    "\n",
    "\n",
    "def simulator_obs(theta, n_obs=100, scale=1.0):\n",
    "    \"\"\"Gaussian likelihood random number generator\"\"\"\n",
    "    return np.random.default_rng().normal(loc=theta, scale=scale, size=(n_obs, theta.shape[0]))\n",
    "\n",
    "\n",
    "generative_model_obs = bf.simulation.GenerativeModel(\n",
    "    prior=prior_obs, simulator=simulator_obs, name=\"Generative Model: Observed\", simulator_is_batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dacb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 simulated data sets from the well-specified model from training (for reference)\n",
    "simulations = trainer.configurator(trainer.generative_model(1000))\n",
    "x = simulations[\"summary_conditions\"]\n",
    "\n",
    "# 1000 \"observed\" data sets with different prior covariance\n",
    "simulations_obs = trainer.configurator(generative_model_obs(1000))\n",
    "x_obs = simulations_obs[\"summary_conditions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11508c3",
   "metadata": {},
   "source": [
    "## Visualization in data space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16aca3b",
   "metadata": {},
   "source": [
    "Let's visualize some of the data $x_{\\text{obs}}$ from that generative model. This plot lives in the data domain $\\mathbb{R}^2$ and depicts the data $x_{\\text{obs}}$. Each color is one data set $k=1,\\ldots,1000$, and all points of one color form the respective data set $x_{\\text{obs}}^{(k)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdeb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_sets_visualization = 10\n",
    "colors = cm.viridis(np.linspace(0, 1, n_data_sets_visualization))\n",
    "indices = list(range(n_data_sets_visualization))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 6))\n",
    "for idx, c in zip(indices, colors):\n",
    "    ax1.scatter(x[idx, :, 0], x[idx, :, 1], color=c, alpha=0.7)\n",
    "    ax2.scatter(x_obs[idx, :, 0], x_obs[idx, :, 1], color=c, alpha=0.7)\n",
    "\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    sns.despine()\n",
    "\n",
    "ax1.set_title(\"data from well-specified model\")\n",
    "ax2.set_title(\"observed data\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd544d",
   "metadata": {},
   "source": [
    "## Detecting misspecification in summary space\n",
    "\n",
    "As proposed in our paper [2], we will detect the deviating observed data as deviations in the structured summary space. Therefore, we compute the learned summary statistics of the well-specified data $h_{\\psi}(x)$ and for the observed data $h_{\\psi}(x_{\\text{obs}})$ by a simple pass through the trainer's summary network $h_{\\psi}$.\n",
    "\n",
    "\n",
    "[2] Schmitt et al (2021): https://arxiv.org/abs/2112.08866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85062ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_statistics = trainer.amortizer.summary_net(x)\n",
    "summary_statistics_obs = trainer.amortizer.summary_net(x_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3cbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "colors = cm.viridis(np.linspace(0.1, 0.9, 2))\n",
    "ax.scatter(\n",
    "    summary_statistics_obs[:, 0], summary_statistics_obs[:, 1], color=colors[0], label=r\"Observed: $h_{\\psi}(x_{obs})$\"\n",
    ")\n",
    "ax.scatter(summary_statistics[:, 0], summary_statistics[:, 1], color=colors[1], label=r\"Well-specified: $h_{\\psi}(x)$\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.2)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bea4e7",
   "metadata": {},
   "source": [
    "The summary space shows a regular pattern and does not fail in an arbitrary way.This visual discrepancy can be quantified in many ways. In this case, we choose the *Maximum Mean Discrepancy*, more specifically its biased estimator [3], as implemented in `bayesflow.computational_utilities.maximum_mean_discrepancy`.\n",
    "The larger the MMD, the more do the samples deviate.\n",
    "\n",
    "[3] Gretton (2012): https://www.jmlr.org/papers/volume13/gretton12a/gretton12a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmd = utils.maximum_mean_discrepancy(summary_statistics, summary_statistics_obs)\n",
    "print(f\"Estimated MMD in summary space: {mmd:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db160622",
   "metadata": {},
   "source": [
    "# Hypothesis test for observed data\n",
    "\n",
    "In real-life modeling scenarios, a researcher might desire to perform inference on observed data $x_{\\text{obs}}$. After training the neural posterior estimator with samples from a generative model $\\mathcal{M}$, the natural question arises: \"Is the model $\\mathcal{M}$ well-specified for the observed data $x_{\\text{obs}}$?\"\n",
    "\n",
    "\n",
    "To answer this question, we can perform a frequentist hypothesis test on the summary MMD distances. First, we need to gather samples from the sampling distribution of MMD under a well-specified model. This is straight-forward because by definition the model $\\mathcal{M}$ is well-specified with respect to itself. Thus, we will generate a reference sample from the training model $\\mathcal{M}$ and estimate the summary MMD to samples from $\\mathcal{M}$ itself.\n",
    "\n",
    "**Note:** It is important that the number of simulated data sets to estimate the sampling distribution of the summary under the null hypothesis matches the number of observed data sets. This is because the MMD estimator is biased and we need comparable values for the sampling distribution and the observed summary MMD. Therefore, the `bayesflow.computational_utilities.compute_mmd_hypothesis_test` function needs either `observed_data` or `n_observed_data_sets` directly to determine the number of data sets for the estimation of the MMD sampling distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68edbb1",
   "metadata": {},
   "source": [
    "We start by creating some observed data $x_{\\text{obs}}$ from the generative model of the trainer. We expect our model to be well-specified for these data (up to the type I error rate of $5\\%$). We simulate and test against 10 \"observed\" data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb59643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 simulated data sets from the well-specified model from training (for reference)\n",
    "observed_data = trainer.configurator(trainer.generative_model(10))\n",
    "\n",
    "MMD_sampling_distribution, MMD_observed = trainer.mmd_hypothesis_test(observed_data, \n",
    "                                                                      num_reference_simulations=1000,\n",
    "                                                                      num_null_samples=500,\n",
    "                                                                      bootstrap=False)\n",
    "_ = bf.diagnostics.plot_mmd_hypothesis_test(MMD_sampling_distribution, MMD_observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df48417a-26a8-4ba2-8bbf-b1264cd99681",
   "metadata": {},
   "source": [
    "Now, let's plug in some observed data from a different generative model. We will use the generative model from above, where the prior covariance is larger. We see that the misspecification is clearly detectable. In practice, we would conclude that our neural posterior estimator $q_{\\phi}$ is not trustworthy and we should reiterate on the generative model we use to train the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152234f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 \"observed\" data sets with different prior covariance (see above)\n",
    "observed_data = trainer.configurator(generative_model_obs(10))\n",
    "\n",
    "MMD_sampling_distribution, MMD_observed = trainer.mmd_hypothesis_test(observed_data, \n",
    "                                                                      num_reference_simulations=1000,\n",
    "                                                                      num_null_samples=500,\n",
    "                                                                      bootstrap=False)\n",
    "_ = bf.diagnostics.plot_mmd_hypothesis_test(MMD_sampling_distribution, MMD_observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653338c-35c7-443c-b7e0-8ec3ed1d4575",
   "metadata": {},
   "source": [
    "We can also speed up the computations by using bootstraps of the reference data to generate the MMD distribution under the null hypothesis (`bootstrap=True`). This is particularly helpful if the simulator is computationally expensive and a large number of simulations is not computationally feasible.\n",
    "\n",
    "Here, we also provide the reference data ourselves, but bootstrapping can be performed either way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfe447-4172-4755-9fdd-29d223ddbb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data = trainer.configurator(trainer.generative_model(10))\n",
    "observed_data = trainer.configurator(generative_model_obs(10))\n",
    "\n",
    "MMD_sampling_distribution, MMD_observed = trainer.mmd_hypothesis_test(observed_data, \n",
    "                                                                      reference_data=reference_data,\n",
    "                                                                      num_reference_simulations=1000,\n",
    "                                                                      num_null_samples=500,\n",
    "                                                                      bootstrap=True)\n",
    "_ = bf.diagnostics.plot_mmd_hypothesis_test(MMD_sampling_distribution, MMD_observed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fc97c-f4f4-49aa-8c2c-6d028b31ee9c",
   "metadata": {},
   "source": [
    "# Sensitivity to Misspecification\n",
    "\n",
    "The submodule `bayesflow.sensitivity` contains functions to analyze the sensitivity of a converged `Trainer` (i.e., the neural posterior estimator) to model misspecification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cf80ac",
   "metadata": {},
   "source": [
    "We start by redefining the generative model with the possibility to increase the model's misspecification through two settings `p1` and `p2`. Therefore, we define a function `generative_model_misspecified(p1, p2)`. The function takes the settings `p1` and `p2` as input and returns a (potentially misspecified) generative model.\n",
    "\n",
    "In our Gaussian example, we let `p1` control the prior location ($\\mu_0=\\mathtt{p1}$) while `p2` controls the scale of a diagonal covariance matrix $\\Sigma_0$ such that $\\Sigma_0=\\mathtt{p2}\\cdot\\mathbb{I}$. In this example, both settings cause prior misspecification. Inducing other types of misspecification (e.g., simulator or noise) follows the same principle.\n",
    "\n",
    "The consequence: If `p1=0` and `p2=1`, the `generative_model_misspecified` function yields the original well-specified model from training. For all other values for `p1` and `p2`, the resulting generative model differs.\n",
    "\n",
    "**Implementation details:** \n",
    "\n",
    "- The `partial` application pattern lets us pre-load the `prior` with custom arguments and pass this pre-loaded function into the generative model. We use this technique to use `p1` and `p2` as parameters in the prior callable.\n",
    "- We skip the generative model's consistency checks and setup outputs via `skip_test=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ed033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def generative_model_misspecified(p1, p2):\n",
    "    prior_ = partial(prior, D=2, mu=p1, sigma=p2)\n",
    "    simulator_ = partial(simulator, scale=1.0)\n",
    "    generative_model_ = bf.simulation.GenerativeModel(prior_, simulator_, simulator_is_batched=False, skip_test=True)\n",
    "    return generative_model_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9afb3b0",
   "metadata": {},
   "source": [
    "In the next step, we provide meta-information for the sensitivity analysis:\n",
    "\n",
    "- Names of the settings `p1` and `p2`: proper axis labels\n",
    "- Range of the settings `p1` and `p2`: defining the experiment's grid\n",
    "- well-specified value for the settings `p1` and `p2` (i.e., `p1=0` and `p2=1` in our example): dashed lines for the baseline configuration in the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_config = {\n",
    "    \"name\": r\"$\\mu_0$ (prior location)\",\n",
    "    \"values\": np.linspace(-0.1, 3.1, num=20),\n",
    "    \"well_specified_value\": 0.0,\n",
    "}\n",
    "p2_config = {\n",
    "    \"name\": r\"$\\tau_0$ (prior scale)\",\n",
    "    \"values\": np.linspace(0.1, 10.1, num=20),\n",
    "    \"well_specified_value\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8c198a",
   "metadata": {},
   "source": [
    "## Computing Sensitivity\n",
    "\n",
    "As described above, the `bf.sensitivity.misspecification_experiment` function requires the converged `Trainer`, the factory for misspecified models, and meta-information on the settings. In addition, the number of posterior samples per simulated data set as well as the total number of simulated data sets per setting configuration can be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e87cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_error, summary_mmd = bf.sensitivity.misspecification_experiment(\n",
    "    trainer=trainer,\n",
    "    generator=generative_model_misspecified,\n",
    "    first_config_dict=p1_config,\n",
    "    second_config_dict=p2_config,\n",
    "    n_posterior_samples=500,\n",
    "    n_sim=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919073b",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317ad22",
   "metadata": {},
   "source": [
    "Model misspecification with respect to both prior location $\\mu_0$ and scale $\\tau_0$ worsen the average posterior recovery in terms of aggregated RMSE. However, the converged posterior approximator seems to be relatively robust against moderate misspecifications in these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bf.sensitivity.plot_model_misspecification_sensitivity(\n",
    "    posterior_error, p1_config, p2_config, plot_config={\"vmin\": None}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01b222",
   "metadata": {},
   "source": [
    "The MMD plot clearly shows that the summary space MMD is lowest when the model is well-specified (coordinates `(0, 1)`). When either the prior location $\\mu_0$ or the prior scale $\\tau_0$ changes, the summary MMD increases and we're alerted of the model misspecification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = bf.sensitivity.plot_model_misspecification_sensitivity(\n",
    "    summary_mmd, p1_config, p2_config, plot_config={\"vmin\": None}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b1b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fabafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
