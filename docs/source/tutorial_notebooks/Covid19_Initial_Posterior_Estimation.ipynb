{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../../..')))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from functools import partial\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.forward_inference import GenerativeModel, Prior, Simulator\n",
    "from bayesflow.networks import InvertibleNetwork, InvariantNetwork\n",
    "from bayesflow.amortized_inference import AmortizedPosterior\n",
    "from bayesflow.trainers import Trainer\n",
    "import bayesflow.diagnostics as diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-warning",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "<br>\n",
    "In this tutorial, we will illustrate how to perform posterior inference on simple, stationary SIR-like models (complex models will be tackled in a further notebook). SIR-like models comprise suitable illustrative examples, since they generate time-series and their outputs represent the results of solving a system of ordinary differential equations (ODEs).\n",
    "\n",
    "The details for tackling stochastic epidemiological models are described in our corresponding paper, which you can consult for a more formal exposition and a more comprehensive treatment of neural architectures:\n",
    "\n",
    "<em>OutbreakFlow: Model-based Bayesian inference of disease outbreak dynamics with invertible neural networks and its application to the COVID-19 pandemics in Germany</em> https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-little",
   "metadata": {},
   "source": [
    "## Defining the Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-chester",
   "metadata": {},
   "source": [
    "As described in our [very first notebook](Intro_Amortized_Posterior_Estimation.ipynb), a generative model consists of a prior (encoding suitable parameter ranges) and a simulator (generating data given simulations). Our underlying model distinguishes between susceptible, $S$, infected, $I$, and recovered, $R$, individuals with infection and recovery occurring at a constant transmission rate $\\lambda$ and constant recovery rate $\\mu$, respectively. The model dynamics are governed by the following system of ODEs:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{dS}{dt} &= -\\lambda\\,\\left(\\frac{S\\,I}{N}\\right) \\\\\n",
    "    \\frac{dI}{dt} &= \\lambda\\,\\left(\\frac{S\\,I}{N}\\right) - \\mu\\,I \\\\\n",
    "    \\frac{dR}{dt} &= \\mu\\,I,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "with $N = S + I + R$ denoting the total population size. For the purpose of forward inference (simulation), we will use a time step of $dt = 1$, corresponding to daily case reports. In addition to the ODE parameters $\\lambda$ and $\\mu$, we consider a reporting delay parameter $L$ and a dispersion parameter $\\psi$, which affect the number of reported infected individuals via a negative binomial disttribution (https://en.wikipedia.org/wiki/Negative_binomial_distribution):\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    I_t^{(obs)} \\sim \\textrm{NegBinomial}(I^{(new)}_{t-L}, \\psi),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In this way, we connect the latent disease model to an observation model, which renders the relationship between parameters and data a stochastic one. Note, that the obsrvation model induces a further parameter $\\psi$, responsible for the dispersion of the noise.\n",
    "Finally, we will also treat the number of initially infected individuals, $I_0$ as an uknown parameter (having its own prior distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-feelings",
   "metadata": {},
   "source": [
    "### Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-median",
   "metadata": {},
   "source": [
    "We will place the following prior distributions over the five model parameters, summarized in the table below:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\text {Table 1. Description of model parameters and corresponding prior distributions}\\\\\n",
    "&\\begin{array}{lcl}\n",
    "\\hline \\hline \\text { Description} & \\text { Symbol } & \\text { Prior Distribution } \\\\\n",
    "\\hline \\hline \\text{Initial transmission rate} & \\text{$\\lambda$} & \\text{$\\textrm{LogNormal}(\\log(0.4), 0.5)$} \\\\\n",
    "\\text{Recovery rate of infected individuals} & \\text{$\\mu$} & \\text{$\\textrm{LogNormal}(\\log(1/8), 0.2)$} \\\\\n",
    "\\text{Reporting delay (lag)} & \\text{$L$} & \\text{$\\textrm{LogNormal}(\\log(8), 0.2)$} \\\\\n",
    "\\text{Number of initially infected individuals} & \\text{$I_0$} & \\text{$\\textrm{Gamma}(2, 20)$} \\\\\n",
    "\\text{Dispersion of the negative binomial distribution} & \\text{$\\psi$} & \\text{$\\textrm{Exponential}(5)$} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "How did we come up with these priors? In this case, we rely on the domain expertise and previous research by https://www.science.org/doi/10.1126/science.abb9789. In addition, the new parameter $\\psi$ follows an exponential distribution, which restricts it to positive numbers. Below is the implementation of these priors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prior():\n",
    "    \"\"\"Generates random draws from the prior.\"\"\"\n",
    "    \n",
    "    lambd = RNG.lognormal(mean=np.log(0.4), sigma=0.5)\n",
    "    mu = RNG.lognormal(mean=np.log(1/8), sigma=0.2)\n",
    "    D = RNG.lognormal(mean=np.log(8), sigma=0.2)\n",
    "    I0 = RNG.gamma(shape=2, scale=20)\n",
    "    psi = RNG.exponential(5)\n",
    "    return np.array([lambd, mu, D, I0, psi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Prior(prior_fun=model_prior, param_names=[r'$\\lambda$', r'$\\mu$', r'$L$', r'$I_0$', r'$\\psi$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-namibia",
   "metadata": {},
   "source": [
    "During training, we will also standardize the prior draws, that is, ensure zero means and unit scale. We will do this purely for technical reasons - neural networks like scaled values. In addition, our current prior ranges differ vastly, so each parameter will contribute disproportionately to the loss function.\n",
    "\n",
    "Here, we will use the `estimate_means_and_stds()` method of a `Prior` instance, which will estimate the prior means and standard deviations from random draws. We could have also just taken the analytic means and standard deviations, but these may not be available in all settings (e.g., implicit priors).\n",
    "\n",
    "<strong>Caution:</strong> Make sure you have a seed or you set a seed whenever you are doing a Monte-Carlo estimation, since your results might differ slightly due to the empirical variation of the estimates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_means, prior_stds = prior.estimate_means_and_stds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-reconstruction",
   "metadata": {
    "code_folding": [
     2,
     14
    ]
   },
   "outputs": [],
   "source": [
    "from scipy.stats import nbinom\n",
    "\n",
    "def convert_params(mu, phi):\n",
    "    \"\"\" Helper function to convert mean/dispersion parameterization of a negative binomial to N and p, \n",
    "    as expected by numpy.\n",
    "    \n",
    "    See https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations\n",
    "    \"\"\"\n",
    "    \n",
    "    r = phi\n",
    "    var = mu + 1 / r * mu ** 2\n",
    "    p = (var - mu) / var\n",
    "    return r, 1 - p\n",
    "\n",
    "def stationary_SIR(params, N, T, eps=1e-5):\n",
    "    \"\"\"Performs a forward simulation from the stationary SIR model given a random draw from the prior,\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract parameters and round I0 and D\n",
    "    lambd, mu, D, I0, psi = params\n",
    "    I0 = np.ceil(I0)\n",
    "    D = int(round(D))\n",
    "    \n",
    "    # Initial conditions\n",
    "    S, I, R = [N-I0], [I0], [0]\n",
    "    \n",
    "    # Reported new cases\n",
    "    C = [I0]\n",
    "    \n",
    "    # Simulate T-1 tiemsteps\n",
    "    for t in range(1, T+D):\n",
    "        \n",
    "        # Calculate new cases\n",
    "        I_new = lambd * (I[-1]*S[-1]/N)\n",
    "        \n",
    "        # SIR equations\n",
    "        S_t = S[-1] - I_new\n",
    "        I_t = np.clip(I[-1] + I_new - mu*I[-1], 0., N)\n",
    "        R_t = np.clip(R[-1] + mu*I[-1], 0., N)\n",
    "        \n",
    "        # Track\n",
    "        S.append(S_t)\n",
    "        I.append(I_t)\n",
    "        R.append(R_t)\n",
    "        C.append(I_new)\n",
    "    \n",
    "    reparam = convert_params(np.clip(np.array(C[D:]), 0, N) + eps, psi)\n",
    "    C_obs = RNG.negative_binomial(reparam[0], reparam[1])\n",
    "    return C_obs[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-reasoning",
   "metadata": {},
   "source": [
    "As you can see, in addition to the parameters, our simulator requires two further arguments: the total population size $N$ and the time horizon $T$. These are quantities over which we can amortize (i.e., context variables), but for this example, we will just use the population of Germany and the first two weeks of the pandemics (i.e., $T=14$), in the same vein as https://www.science.org/doi/10.1126/science.abb9789."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-queen",
   "metadata": {},
   "source": [
    "### Loading Real Data\n",
    "\n",
    "We will define a simple helper function to load the actually reported cases for the first 2 weeks in Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Helper function to load cumulative cases and transform them to new cases.\"\"\"\n",
    "    \n",
    "    confirmed_cases_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    confirmed_cases = pd.read_csv(confirmed_cases_url, sep=',')\n",
    "\n",
    "    date_data_begin = datetime.date(2020,3,1)\n",
    "    date_data_end = datetime.date(2020,3,15)\n",
    "    format_date = lambda date_py: '{}/{}/{}'.format(date_py.month, date_py.day,\n",
    "                                                     str(date_py.year)[2:4])\n",
    "    date_formatted_begin = format_date(date_data_begin)\n",
    "    date_formatted_end = format_date(date_data_end)\n",
    "\n",
    "    cases_obs =  np.array(\n",
    "        confirmed_cases.loc[confirmed_cases[\"Country/Region\"] == \"Germany\", \n",
    "                            date_formatted_begin:date_formatted_end])[0]\n",
    "    new_cases_obs = np.diff(cases_obs)\n",
    "    return new_cases_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-viking",
   "metadata": {},
   "source": [
    "We then collect the context and real data into a Python dictionary for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'T': 14,\n",
    "    'N': 83e6,\n",
    "    'obs_data': load_data()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-cincinnati",
   "metadata": {},
   "source": [
    "Since we won't vary the context variables during training, we can also define our simulator with fixed keyword arguments with the help of the `partial` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(\n",
    "    simulator_fun=partial(stationary_SIR, T=config['T'], N=config['N'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-repeat",
   "metadata": {},
   "source": [
    "Thus, whenever we call the `simulator` object, it will always use the keyword arguments provided to the `partial` function. Also, pay attention that we are passing the simulator function as a `simulator_fun` argument. A `Simulator` instance can also be initialized with a `batched_simulator_fun`, which implies that the simulator works on multiple (batched), instead of single, random draws from the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-tokyo",
   "metadata": {},
   "source": [
    "### Generative Model\n",
    "\n",
    "We now connect the prior and the simulator through the `GenerativeModel` wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(prior, simulator, name='basic_covid_simulator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-cleaner",
   "metadata": {},
   "source": [
    "## Prior Checking\n",
    "\n",
    "Any principled Bayesian workflow requires some prior predictive or prior pushforward checks to ensure that the prior specification is consistent with domain expertise (see https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html). The BayesFlow library provides some rudimentary visual tools for performing prior checking. For instance, we can visually inspect the joint prior in the form of bivariate plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As per default, the plot_prior2d function will obtain 1000 draws from the joint prior.\n",
    "f = prior.plot_prior2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-discrimination",
   "metadata": {},
   "source": [
    "## Defining the Neural Approximator\n",
    "\n",
    "We can now proceed to define our BayesFlow neural architecture, that is, combine a summary network with an invertible inference network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-colors",
   "metadata": {},
   "source": [
    "### Summary Network\n",
    "\n",
    "Since our simulator outputs 3D tensors of shape ``(batch_size, T = 14, 1)``, we need to reduce this three dimensional tensor into a 2D tensor of shape ``(batch_size, summary_dim``. Our model outputs are so simple, that we cn actually just remove the trailing dimension of the raw outputs and simply feed the data directly to the inference network.\n",
    "\n",
    "However, for the purpose of illustration (and generalization), we will create a more inolved summary network consisting of 1D convolutional layers (https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/blocks/1d-convolution) followed by a Long Short-Term Memory (LSTM) network (https://colah.github.io/posts/2015-08-Understanding-LSTMs/). Such an architecture not only does what we want, but also generalizes to much more complex models and longer time-series, see for instance our ``OutbreakFlow`` architecture:\n",
    "\n",
    "https://arxiv.org/abs/2010.00300\n",
    "\n",
    "Feel free to experiment with different summary architectures as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(tf.keras.Model):\n",
    "    def __init__(self, n_summary):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.conv =  tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv1D(n_summary, kernel_size=3, strides=1, \n",
    "                                   padding='causal', activation='relu', kernel_initializer='glorot_uniform'),\n",
    "            tf.keras.layers.Conv1D(n_summary*2, kernel_size=2, strides=1, \n",
    "                                   padding='causal', activation='relu', kernel_initializer='glorot_uniform'),\n",
    "            tf.keras.layers.Conv1D(n_summary*3, kernel_size=1, strides=1, \n",
    "                                   padding='causal', activation='relu', kernel_initializer='glorot_uniform')\n",
    "        ])\n",
    "        self.lstm = tf.keras.layers.LSTM(n_summary)\n",
    "\n",
    "    def call(self, x, **args):\n",
    "        \"\"\"x is a timeseries of dimensiosns B timestamps, n_features\"\"\"\n",
    "\n",
    "        out = self.conv(x)\n",
    "        out = self.lstm(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = ConvLSTM(n_summary=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-contract",
   "metadata": {},
   "source": [
    "### Inference Network\n",
    "\n",
    "\n",
    "For the inference network, we can just change the default number of `n_coupling_layers` from $4$ to $3$, in order to accelerate training a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_net = InvertibleNetwork({\n",
    "    'n_params': 5, \n",
    "    'n_coupling_layers': 3, \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-surprise",
   "metadata": {},
   "source": [
    "### Amortized Posterior\n",
    "\n",
    "We can now connect the summary and inference networks via the `AmortizedPosterior` wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer = AmortizedPosterior(inference_net, summary_net, name='covid_amortizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-welcome",
   "metadata": {},
   "source": [
    "Note, that the `name` keyword argument is optional, but it is good practice to name your models and amortizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-nicaragua",
   "metadata": {},
   "source": [
    "# Configurator\n",
    "\n",
    "As a reminder, a configurator acts as an intermediary between a generative model and an amortizer:\n",
    "\n",
    "<img src=img/trainer_connection.png width=75%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-combining",
   "metadata": {},
   "source": [
    "In other words, we need to ensure the outputs of the forward model are suitable for processing with neural networks. Currently, they are not, since our data $\\boldsymbol{x}_{1:T}$ consists of large integer (count) values. However, neural networks like scaled data. Furthermore, our parameters $\\boldsymbol{\\theta}$ exhibit widely different scales due to their prior specification and role in the simulator, so will standardize them using our previously copmputed prior means and standard deviations. In addition, ODE models are prone to divergences and exploding outputs, which will mess up our training. So, in sum, our configurator does the following:\n",
    "\n",
    "1. Initializes a new dictionary (line 7).\n",
    "2. Performs a log-transform on the simulated data and convert it to `float32` type (line 10).\n",
    "3. Converts the prior draws to `float32` type and standardizes them (lines 13 - 14).\n",
    "4. Removes potentially problematic simulations from the batch (lines 17 - 19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_input(forward_dict):\n",
    "    \"\"\" Function to configure the simulated quantities (i.e., simulator outputs)\n",
    "    into a neural network-friendly (BayesFlow) format.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare placeholder dict\n",
    "    out_dict = {}\n",
    "    \n",
    "    # Convert data to logscale \n",
    "    logdata = np.log1p(forward_dict['sim_data']).astype(np.float32)\n",
    "    \n",
    "    # Extract prior draws and z-standardize with previously computed means\n",
    "    params = forward_dict['prior_draws'].astype(np.float32)\n",
    "    params = (params - prior_means) / prior_stds\n",
    "    \n",
    "    # Remove a batch if it contains nan, inf or -inf\n",
    "    idx_keep = np.all(np.isfinite(logdata), axis=(1, 2))\n",
    "    if not np.all(idx_keep):\n",
    "        print('Invalid value encountered...removing from batch')\n",
    "    \n",
    "    # Add to keys\n",
    "    out_dict['summary_conditions'] = logdata[idx_keep]\n",
    "    out_dict['parameters'] = params[idx_keep]\n",
    "    \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-eclipse",
   "metadata": {},
   "source": [
    "## Defining the Trainer\n",
    "\n",
    "Finally, we are in a position to define our `Trainer` instance. Notice that we also pass out custom `configurator` function to the constructer. The default configurator won't do in this case!\n",
    "\n",
    "Note, that you should supply a `checkpoint_path` for the `Trainer` instance, if you don't want to save the neural approximators manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change var_obs\n",
    "trainer = Trainer(amortizer=amortizer, \n",
    "                  generative_model=model, \n",
    "                  configurator=configure_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-healthcare",
   "metadata": {},
   "source": [
    "Great, the trainer informs us, that the consistency check (i.e., simulation -> configuration -> transformation -> loss computation) was successful. We can now train our networks on epidemiological simulations. We can also check our the number of trainable neural network parameters for this approximator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-teens",
   "metadata": {},
   "source": [
    "## Training Phase\n",
    "\n",
    "Ready to train! Since our simulator is pretty fast, we can safely go with online training. Let's glean the time taken for a batch of $32$ simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = model(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = trainer.train_online(epochs=5, iterations_per_epoch=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-cardiff",
   "metadata": {},
   "source": [
    "### Inspecting the Loss\n",
    "\n",
    "We can quickly visualize the loss trajectory using the `plot_losses` function from the `diagnostics` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = diag.plot_losses(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-colon",
   "metadata": {},
   "source": [
    "### Inspecting the Latent Space\n",
    "\n",
    "A quick and useful diagnostic is to check whether the marginal latent distribution $p(\\boldsymbol{z})$ has the prescribed probabilistic structure. Since, by default, we optimize the amortizer with the Kullback-Leibler (KL) loss (also known as maximum likelihood training, which is not to be confused with maximum likelihood estimation!), we expect to observe approximately Gaussian latent space with independent axes. Moreover, since the trainer also keeps an internal `SimulatioMemory` instance, we can also directly call it's `diagnose_latent2d` method (also available in the `diagnostics` module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = trainer.diagnose_latent2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-florida",
   "metadata": {},
   "source": [
    "### Simulation-Based Calibration - Rank Histograms\n",
    "\n",
    "As a further <strong>small world</strong> (i.e., before real data) sanity check, we can also test the calibration of the amortizer through simulation-based calibration (SBC). See the corresponding paper by Sean Talts, Michael Betancourt, Daniel Simpson, Aki Vehtari, and Andrew Gelman for more details:\n",
    "\n",
    "https://arxiv.org/pdf/1804.06788.pdf\n",
    "\n",
    "Accordingly, we expect to observe approximately uniform rank statistic histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-nickname",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = trainer.diagnose_sbc_histograms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-space",
   "metadata": {},
   "source": [
    "### Simulation-Based Calibration - Rank ECDF\n",
    "\n",
    "For models with many parameters, inspecting many histograms can become unwieldly. Moreover, the `num_bins` hyperparameter for the construction of SBC rank histograms can be hard to choose. An alternative diagnostic approach for calibration is through empirical cumulative distribution functions (ECDF) of rank statistics. You can read more about this approach in the corresponding paper by Teemu Säilynoja, Paul-Christian Bürkner, and Aki Vehtari:\n",
    "\n",
    "https://arxiv.org/abs/2103.10522\n",
    "\n",
    "In order to inspect the ECDFs of marginal distributions, we will simulate $300$ new pairs $(\\boldsymbol{x}, \\boldsymbol{\\theta})$ and use the function `plot_sbc_ecdf` from the `diagnostics` module: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some validation data\n",
    "validation_sims = trainer.configurator(model(batch_size=300))\n",
    "\n",
    "# Draw samples\n",
    "post_samples = amortizer.sample(validation_sims, n_samples=100)\n",
    "\n",
    "# Create plot\n",
    "f = diag.plot_sbc_ecdf(post_samples, validation_sims['parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-hypothetical",
   "metadata": {},
   "source": [
    "## Inference Phase\n",
    "\n",
    "We can now move on to using real data. As an importnat general remark: remember that the real and simulated data need to be in the same format (i.e., discrete indicators should be one-hot-encoded, transformations during training should also be applied during inference, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-safety",
   "metadata": {},
   "source": [
    "### Inferential Adequacy (Global)\n",
    "\n",
    "Depending on the application, it might be interesting to see how well summaries of the full posterior (e.g., means, medians) recover the assumed true parameter values. We can test this <em>in silico</em> via the `plot_recovery` function in the `diagnostics` module. For instance, we can compare how well posterior means recover the true parameter (i.e., posterior z-score, https://betanalpha.github.io/assets/case_studies/principled_bayesian_workflow.html). Below, we re-use the $300$ simulations we took for computing the rank ECDFs, but obtain a larger number of posterior draws per data set for more stable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples = amortizer.sample(validation_sims, n_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = diag.plot_recovery(post_samples, validation_sims['parameters'], param_names=prior.param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-trunk",
   "metadata": {},
   "source": [
    "### Bivariate Posteriors\n",
    "\n",
    "Finally, we can feed the real case data from the first two weeks and inspect the approximate posteriors or obtain model-based predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data into a 3D array of shape (1, n_time_steps, 1) and perform log transform\n",
    "obs_data = np.log1p(config['obs_data'])[np.newaxis, :, np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain 500 posterior draws given real data\n",
    "post_samples = amortizer.sample({'summary_conditions': obs_data}, 500)\n",
    "\n",
    "# Undo standardization to get parameters on their original (unstandardized) scales\n",
    "post_samples = prior_means + post_samples * prior_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-alexander",
   "metadata": {},
   "source": [
    "#### Standalone\n",
    "\n",
    "Using the `plot_posterior_2d` function from the `diagnostics` module, we can look at the bivariate posteriors in isolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = diag.plot_posterior_2d(post_samples, param_names=prior.param_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-change",
   "metadata": {},
   "source": [
    "#### Compared to Prior\n",
    "\n",
    "In addition, we can have a more informative plot which indicates the Bayesian surprise (i.e., difference between prior and posterior) by also supplying the prior object to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = diag.plot_posterior_2d(post_samples, prior=prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-mouth",
   "metadata": {},
   "source": [
    "### Posterior Retrodictive Checks\n",
    "\n",
    "These are also called <em>posterior predictive checks</em>, but here we want to explicitly highlight the fact that we are not predicting future data but testing the <strong>generative performance</strong> or <strong>re-simulation performance</strong> of the model. In other words, we want to test how well the simulator can reproduce the actually observed data given the parameter posterior $p(\\boldsymbol{\\theta} | \\boldsymbol{x}_{1:T})$. \n",
    "\n",
    "Here, we will create a custom function which plots and data and then overlays draws from the posterior predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ppc(config, post_samples, logscale=True, color='Blue', \n",
    "                            dummy=True, figsize=(12, 6), font_size=18):\n",
    "    \"\"\"\n",
    "    Helper function to perform some plotting of the posterior predictive.\n",
    "    \"\"\"\n",
    "    # Plot settings\n",
    "    plt.rcParams['font.size'] = font_size\n",
    "    \n",
    "    # Remove parameters < 0\n",
    "    samples = post_samples[np.sum(post_samples < 0, axis=1) == 0]\n",
    "    \n",
    "    f, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    # Re-simulations\n",
    "    sims = []\n",
    "    for i in range(samples.shape[0]):  \n",
    "        # Note - simulator returns 2D arrays of shape (T, 1), so we remove trailing dim \n",
    "        sim_cases = stationary_SIR(samples[i], config['N'], config['T'])[:, 0]\n",
    "        sims.append(sim_cases)\n",
    "    sims = np.array(sims)\n",
    "    \n",
    "    # Compute quantils for each t = 1,...,T\n",
    "    qs_50 = np.quantile(sims, q=[0.25, 0.75], axis=0)\n",
    "    qs_90 = np.quantile(sims, q=[0.05, 0.95], axis=0)\n",
    "    qs_95 = np.quantile(sims, q=[0.025, 0.975], axis=0)\n",
    "    \n",
    "    # PLot median predictions and observed data\n",
    "    ax.plot(np.median(sims, axis=0), label='Median predicted cases', color=color)\n",
    "    ax.plot(config['obs_data'], marker='o', label='Reported cases', color='black', linestyle='dashed', alpha=0.8)\n",
    "    \n",
    "    # Add compatibility intervals (also called credible intervals)\n",
    "    ax.fill_between(range(config['T']), qs_50[0], qs_50[1], color=color, alpha=0.3, label='50% CI')\n",
    "    ax.fill_between(range(config['T']), qs_90[0], qs_90[1], color=color, alpha=0.2, label='90% CI')\n",
    "    ax.fill_between(range(config['T']), qs_95[0], qs_95[1], color=color, alpha=0.1, label='95% CI')\n",
    "    \n",
    "    # Grid and schmuck\n",
    "    ax.grid(color='grey', linestyle='-', linewidth=0.25, alpha=0.5)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_xlabel('Days since pandemic onset')\n",
    "    ax.set_ylabel('Number of cases')\n",
    "    ax.minorticks_off()\n",
    "    if logscale:\n",
    "        ax.set_yscale('log')\n",
    "    ax.legend(fontsize=font_size)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-doctrine",
   "metadata": {},
   "source": [
    "We can now go on and plot the re-simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_ppc(config, post_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-narrative",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "0613a290875d2e45ed6a913053ba0bd854769bb3ccf72d12c85710ab11271e35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
