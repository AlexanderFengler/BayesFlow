<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Defining the Generative Model &mdash; BayesFlow beta documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> BayesFlow
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../modules.html">bayesflow</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">BayesFlow</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
      <li class="breadcrumb-item active">Defining the Generative Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorial_notebooks/Intro_Amortized_Posterior_Estimation.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;../../..&#39;</span><span class="p">)))</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">bayesflow.simulation</span> <span class="kn">import</span> <span class="n">GenerativeModel</span><span class="p">,</span> <span class="n">Prior</span><span class="p">,</span> <span class="n">Simulator</span>
<span class="kn">from</span> <span class="nn">bayesflow.networks</span> <span class="kn">import</span> <span class="n">InvertibleNetwork</span><span class="p">,</span> <span class="n">InvariantNetwork</span>
<span class="kn">from</span> <span class="nn">bayesflow.amortizers</span> <span class="kn">import</span> <span class="n">AmortizedPosterior</span>
<span class="kn">from</span> <span class="nn">bayesflow.trainers</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="kn">import</span> <span class="nn">bayesflow.diagnostics</span> <span class="k">as</span> <span class="nn">diag</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
C:\Users\Stefan Radev\Desktop\Projects\BayesFlow\bayesflow\simulation.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)
  from tqdm.autonotebook import tqdm
</pre></div></div>
</div>
<h1><p>Introduction</p>
</h1><p>Welcome to the very first tutorial on using BayesFlow for amortized posterior estimation! In this notebook, we will estimate the means of a multivariate Gaussian model and illustrate some features of the library along the way. Above, we have already imported the core entities we will need for this notebook. In brief:</p>
<ul class="simple">
<li><p>The module <code class="docutils literal notranslate"><span class="pre">simulations</span></code> contains high-level wrappers for gluing together priors, simulators, and context generators into a single <code class="docutils literal notranslate"><span class="pre">GenerateModel</span></code> object, which will generate all quantities of interest for a modeling scenario.</p></li>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">networks</span></code> contains the core neural architectures used for various tasks, e.g., an <code class="docutils literal notranslate"><span class="pre">InvertibleNetwork</span></code> for realizing normalizing flows (<a class="reference external" href="https://paperswithcode.com/method/normalizing-flows">https://paperswithcode.com/method/normalizing-flows</a>) or an <code class="docutils literal notranslate"><span class="pre">InvariantNetwork</span></code> for learning permutation-invariant summary representations (embeddings).</p></li>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">amortizers</span></code> contains high-level wrappers which connect the various networks together and instruct them about their particular goals in the inference pipeline.</p></li>
<li><p>The module <code class="docutils literal notranslate"><span class="pre">trainers</span></code> contains high-level wrappers for dictating the training phase of an amortized posterior. Typically, the standard <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> will take care of most scenarios.</p></li>
</ul>
<p>The nuts and bolts of using BayesFlow for Bayesian parameter estimation have already been described in the corresponding papers: * BayesFlow: Learning complex stochastic models with invertible neural networks <a class="reference external" href="https://arxiv.org/abs/2003.06281">https://arxiv.org/abs/2003.06281</a> * Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks <a class="reference external" href="https://arxiv.org/abs/2112.08866">https://arxiv.org/abs/2112.08866</a></p>
<p>At a high level, our architecture consists of a summary network <span class="math notranslate nohighlight">\(h\)</span> and an inference network <span class="math notranslate nohighlight">\(f\)</span> which jointly amortize a generative model. The summary network transforms input data <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> of potentially variable size to a fixed-length representations. The inference network generates random draws from an approximate posterior <span class="math notranslate nohighlight">\(q\)</span> via a conditional invertible neural network (cINN). This process is illustrated in the figure below:</p>
<p><img alt="6c5be8363a8e4c5fa1a0ec2089e05279" class="no-scaled-link" src="../_images/bayesflow_overview.png" style="width: 90%;" /></p>
<p>The left panel illustrates the training phase. During this phase, only the model (i.e., simulator and prior) is used to jointly train the summary and inference networks. The right panel illustrates the inference phase. During this phase, arbitrarily many actually observed data sets can be fed through the networks to obtain posteriors. For instance, in one recent paper (<a class="reference external" href="https://www.nature.com/articles/s41562-021-01282-7">https://www.nature.com/articles/s41562-021-01282-7</a>), the authors applied pre-trained networks to more than one million observed
data sets! Now let’s get into some coding…</p>
<p>First and foremost, we set a local seed for reproducibility (best practice as of 2022).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RNG</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2022</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Defining-the-Generative-Model">
<h1>Defining the Generative Model<a class="headerlink" href="#Defining-the-Generative-Model" title="Permalink to this heading"></a></h1>
<p>From the perspective of the BayesFlow framework, a generative model is more than just a prior and a simulator. In addition, it consists of various implicit context assumptions, which we can make explicit at any time. Furthermore, we can also amortize over these context variables, thus making our real-world inference more flexible (i.e., applicable to more contexts). The figure below illustrates the skeleton of a generative model as conceptualized in the BayesFlow framework.</p>
<p><img alt="15d83e53342f401f94cc1210e276774c" class="no-scaled-link" src="../_images/generative_model.png" style="width: 75%;" /></p>
<p>This conceptual model allows you to tackle very flexible model families with BayesFlow, as well as various other Bayesian tasks, such as prior sensitivity analysis or multiverse analysis.</p>
<p>The toy Gaussian model we will use for this tutorial takes a particularly simple form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
 \boldsymbol{\mu} &amp;\sim \mathcal{N}_D(\boldsymbol{0}, \sigma_0\mathbb{I}) \\
 \boldsymbol{x}_n &amp;\sim \mathcal{N}_D(\boldsymbol{\mu}, \sigma_1\mathbb{I})\quad\textrm{ for } n = 1,..,N,
\end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{N}_D\)</span> denotes a multivariate Gaussian (normal) density with <span class="math notranslate nohighlight">\(D\)</span> dimensions, which we set at <span class="math notranslate nohighlight">\(D = 4\)</span> for the current example. For simplicity, we will also set <span class="math notranslate nohighlight">\(\sigma_0 =1\)</span> and <span class="math notranslate nohighlight">\(\sigma_1 = 1\)</span>. We will now implement this model using the latest numpy interface.</p>
<section id="Prior">
<h2>Prior<a class="headerlink" href="#Prior" title="Permalink to this heading"></a></h2>
<p>We first define a function generating single draws from the prior (as specified by our model formulation above), which we pass to the <code class="docutils literal notranslate"><span class="pre">Prior</span></code> wrapper.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior_fun</span><span class="p">(</span><span class="n">D</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RNG</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span> <span class="o">=</span> <span class="n">Prior</span><span class="p">(</span><span class="n">prior_fun</span><span class="o">=</span><span class="n">prior_fun</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>That’s it. The <code class="docutils literal notranslate"><span class="pre">Prior</span></code> object is now callable with a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> argument which dictates how many draws are generated from the prior. We can take a look at the outputs of the prior by doing:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;prior_draws&#39;: array([[ 2.67641529, -0.84279441,  2.07818003, -1.52765993],
        [ 0.39617851, -0.09590611, -2.47541091, -0.36716256],
        [ 0.59226504, -2.9312485 , -1.44023358,  0.07888769],
        [ 0.5856408 ,  1.66771611, -1.14089297, -0.20990006],
        [ 0.49681204,  1.01997171, -0.88286937, -1.33132135],
        [ 2.02567893,  0.81655117,  0.46034347,  0.17473455],
        [-0.72613673, -0.88523628, -1.61728344, -0.86198073],
        [-0.86489883,  0.56664501, -1.12666878, -1.44500009],
        [ 0.24692666,  1.23418102,  0.00576552,  0.53346655],
        [-1.15443727, -0.29927867,  2.15587299,  0.1004425 ]]),
 &#39;batchable_context&#39;: None,
 &#39;non_batchable_context&#39;: None}
</pre></div></div>
</div>
<p>Wow! The prior generated some other stuff that we never specified and packed it into a Python <code class="docutils literal notranslate"><span class="pre">dict</span></code>. That definitely needs some explanation. Remember our picture above? A prior can also accept context variables which modify its behavior, whenever this is desirable. We will see this when we illustrate how to perform prior sensitivity analysis. We also see two types of context variables. These are worth mentioning as well. The interface distinguishes between two types of context:
<code class="docutils literal notranslate"><span class="pre">batchable_context</span></code> and <code class="docutils literal notranslate"><span class="pre">non_batchable_context</span></code>. This distinction is a purely technical, rather then a conceptual one: * Batchable context variables differ for each simulation in each training batch of simulations; * Non-batchable context variables stay the same for each simulation in a batch, but differ across simulated batches;</p>
<p>Examples for batchable context variables include experimental design variables, design matrices, etc. Examples for non-batchable context variables include the number of observations in an experiment, positional encodings, time indices, etc. While the latter can also be considered batchable in principle, batching them would require non-Tensor (i.e., non-rectangular) data structures, which usually means inefficient computations.</p>
</section>
<section id="Simulator">
<h2>Simulator<a class="headerlink" href="#Simulator" title="Permalink to this heading"></a></h2>
<p>In this case, our simulator function is equally simple to our prior function. We will call it a likelihood function, in correspondence with standard Bayesian terminology, and pass it to the <code class="docutils literal notranslate"><span class="pre">Simulator</span></code> wrapper.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood_fun</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">n_obs</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">RNG</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_obs</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulator</span> <span class="o">=</span> <span class="n">Simulator</span><span class="p">(</span><span class="n">simulator_fun</span><span class="o">=</span><span class="n">likelihood_fun</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note, that we define our <code class="docutils literal notranslate"><span class="pre">simulator_fun</span></code> with two arguments. A positional argument which stands for a single random draw from the prior and a keyword argument <code class="docutils literal notranslate"><span class="pre">n_obs</span></code> which represents the number of observations <span class="math notranslate nohighlight">\(N\)</span> we will generate from the likelihood for each draw from the prior. As some point, we want to vary <span class="math notranslate nohighlight">\(N\)</span> during training, so that the architecture can generalize to different <span class="math notranslate nohighlight">\(N\)</span> during inference.</p>
</section>
<section id="Generative-Model">
<h2>Generative Model<a class="headerlink" href="#Generative-Model" title="Permalink to this heading"></a></h2>
<p>We will now connect the prior with the likelihood (simulator) via the <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> interface:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">GenerativeModel</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span> <span class="n">simulator</span><span class="o">=</span><span class="n">simulator</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO:root:Performing 2 pilot runs with the anonymous model...
INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 4)
INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 50, 4)
INFO:root:No optional prior non-batchable context provided.
INFO:root:No optional prior batchable context provided.
INFO:root:No optional simulation non-batchable context provided.
INFO:root:No optional simulation batchable context provided.
</pre></div></div>
</div>
<p>The generative model will also provide an internal consistency check and report on the tensor shapes of the different quantities output by the model. We can also manually inspect its outputs for <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">3</span></code> (i.e., three simulations):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&#39;prior_non_batchable_context&#39;, &#39;prior_batchable_context&#39;, &#39;prior_draws&#39;, &#39;sim_non_batchable_context&#39;, &#39;sim_batchable_context&#39;, &#39;sim_data&#39;]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of sim_data: &#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">[</span><span class="s1">&#39;sim_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of sim_data:  (3, 50, 4)
</pre></div></div>
</div>
<p>The output of the <code class="docutils literal notranslate"><span class="pre">GenerativeModel</span></code> is also a Python <code class="docutils literal notranslate"><span class="pre">dict</span></code> with even more keys than before. You should probably have an intuition what these keys represent, namely, the different types of context variables (none in this case) for prior and simulator. With this simple set-up, we can now proceed to do some posterior estimation.</p>
</section>
</section>
<section id="Defining-the-Neural-Approximator">
<h1>Defining the Neural Approximator<a class="headerlink" href="#Defining-the-Neural-Approximator" title="Permalink to this heading"></a></h1>
<section id="Summary-Network">
<h2>Summary Network<a class="headerlink" href="#Summary-Network" title="Permalink to this heading"></a></h2>
<p>Since our likelihood generates data exchangeably, we need to respect the permutation invariance of the data. For that, we will use an <code class="docutils literal notranslate"><span class="pre">InvariantNetwork</span></code> which does exactly that. This network will take (at least) 3D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">n_obs,</span> <span class="pre">D)</span></code> and reduce them to 2D tensors of shape <code class="docutils literal notranslate"><span class="pre">(batch_size,</span> <span class="pre">summary_dim)</span></code>, where <code class="docutils literal notranslate"><span class="pre">summary_dim</span></code> is a hyperparameter to be set by the user (you). Heuristically, this number should not be lower than the number of parameters in a model. Below, we
create an invariant network with <code class="docutils literal notranslate"><span class="pre">summary_dim</span> <span class="pre">=</span> <span class="pre">10</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_net</span> <span class="o">=</span> <span class="n">InvariantNetwork</span><span class="p">(</span><span class="n">summary_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note, that the hyperparameter setting for the <code class="docutils literal notranslate"><span class="pre">InvariantNetwork</span></code> are all provided inside a single Python dictionary. It helps to inspect the outputs of the summary network manually and confirm its operation:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_inp</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">summary_rep</span> <span class="o">=</span> <span class="n">summary_net</span><span class="p">(</span><span class="n">test_inp</span><span class="p">[</span><span class="s1">&#39;sim_data&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of simulated data sets: &#39;</span><span class="p">,</span> <span class="n">test_inp</span><span class="p">[</span><span class="s1">&#39;sim_data&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of summary vectors: &#39;</span><span class="p">,</span> <span class="n">summary_rep</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of simulated data sets:  (3, 50, 4)
Shape of summary vectors:  (3, 10)
</pre></div></div>
</div>
<p>It is these summary vectors that will enter as conditions for the inference network. Upon convergence of the simulation-based training, we can think of them as learned summary statistics or data embeddings.</p>
</section>
<section id="Inference-Network">
<h2>Inference Network<a class="headerlink" href="#Inference-Network" title="Permalink to this heading"></a></h2>
<p>Next we define the main workhorse of our our framework for amortized posterior inference - the conditional invertible neural network (cINN). The only mandatory hyperparameter for the <code class="docutils literal notranslate"><span class="pre">InvertibleNetwork</span></code> is the number of parameters we aim to estimate, in our case <code class="docutils literal notranslate"><span class="pre">num_params</span> <span class="pre">=</span> <span class="pre">4</span></code>. However, we can change some more, for instance set the number of coupling layers <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span> <span class="pre">=</span> <span class="pre">2</span></code>, which will make training faster than using the default <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span> <span class="pre">=</span> <span class="pre">4</span></code>, but also reduce the
expressiveness (performance) of our network. Naturally, we don’t need a lot of expressiveness for our trivial Gaussian model, so we can proceed with <code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span> <span class="pre">=</span> <span class="pre">2</span></code>.</p>
<p>The invertible inference network has the following further hyperparameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_params</span></code> (mandatory) - the number of model parameters (eq. the dimensionality of the latent space).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">num_coupling_layers</span></code> - the number of invertible layers. The more layers, the more powerful the network, but the slower and less stable the training. Typically <span class="math notranslate nohighlight">\(4 - 8\)</span> coupling layers should be sufficient.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coupling_net_settings</span></code> - the settings for the internal coupling layers. Typically, the defaults work well, but small regularization should be added for</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">coupling_design</span></code> - Normally, you would not touch this.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">soft_clamping</span></code> - The soft-clamping parameter. Just use the default value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_permutation</span></code> - Whether to use permutations before each coupling layer. Should be used by default.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_act_norm</span></code> - Whether to apply activation normalization after each coupling layer. Works well in practice and stabilizes training.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">act_norm_init</span></code> - In some cases, you can perform data-dependend initialization of the <code class="docutils literal notranslate"><span class="pre">ActNorm</span></code> layers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_soft_flow</span></code> - Whether to use a SoftFlow architecture (<a class="reference external" href="https://arxiv.org/abs/2006.04604">https://arxiv.org/abs/2006.04604</a>). Useful for degenerate distributions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">soft_flow_bounds</span></code> - The bounds for the varying standard deviation of SoftFlow’s noise. Do not touch, unless you have good reasons to.</p></li>
</ul>
<p>You can glean all the defaults in the <code class="docutils literal notranslate"><span class="pre">default_settings</span></code> module. For most applications, you only need to define the <code class="docutils literal notranslate"><span class="pre">n_params</span></code> and <code class="docutils literal notranslate"><span class="pre">n_coupling_layers</span></code> hyperparameters</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inference_net</span> <span class="o">=</span> <span class="n">InvertibleNetwork</span><span class="p">(</span><span class="n">num_params</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">num_coupling_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Again, we can inspect the raw outputs of the cINN by feeding it the parameter draws and corresponding data summaries. This network is slightly more involved than the summary network, as it has two mandatory inputs: <code class="docutils literal notranslate"><span class="pre">targets</span></code> and <code class="docutils literal notranslate"><span class="pre">condition</span></code>. It also has two outputs: <code class="docutils literal notranslate"><span class="pre">z</span></code> and <code class="docutils literal notranslate"><span class="pre">log_det_J</span></code>, which represent the latent representation of the parameters and the log of the Jacobian determinant, respectively.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span><span class="p">,</span> <span class="n">log_det_J</span> <span class="o">=</span> <span class="n">inference_net</span><span class="p">(</span><span class="n">test_inp</span><span class="p">[</span><span class="s1">&#39;prior_draws&#39;</span><span class="p">],</span> <span class="n">summary_rep</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We can inspect the shapes of the outputs as well:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of latent variables:&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of log det Jacobian:&#39;</span><span class="p">,</span> <span class="n">log_det_J</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of latent variables: (3, 4)
Shape of log det Jacobian: (3,)
</pre></div></div>
</div>
</section>
<section id="Amortized-Posterior">
<h2>Amortized Posterior<a class="headerlink" href="#Amortized-Posterior" title="Permalink to this heading"></a></h2>
<p>We can now connect the <code class="docutils literal notranslate"><span class="pre">summary_net</span></code> and the <code class="docutils literal notranslate"><span class="pre">inference_net</span></code> via the high-level wrapper <code class="docutils literal notranslate"><span class="pre">AmortizedPosterior</span></code>. This wrapper knows how to compute its loss function, draw samples from the approximate posterior given new data and also compute normalized posterior densities.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">amortizer</span> <span class="o">=</span> <span class="n">AmortizedPosterior</span><span class="p">(</span><span class="n">inference_net</span><span class="p">,</span> <span class="n">summary_net</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Defining-the-Trainer">
<h1>Defining the Trainer<a class="headerlink" href="#Defining-the-Trainer" title="Permalink to this heading"></a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance connects a generative model with an amortizer and enables various types of simulation-based training. Actually, it has only a single mandatory argument, <code class="docutils literal notranslate"><span class="pre">amortizer</span></code>, which expect an <code class="docutils literal notranslate"><span class="pre">Amortized*</span></code> instance. However, in order to be able to perform on-the-fly simulation-based training (see below), we also need to provide the generative model. Note, that the generative model does not need to use our provided wrappers, but the keys of its dictionary output should adhere to
BayesFlow’s expectations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">amortizer</span><span class="o">=</span><span class="n">amortizer</span><span class="p">,</span>
                  <span class="n">generative_model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO:root:Performing a consistency check with provided components...
INFO:root:Done.
</pre></div></div>
</div>
<p>Actually, a <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance does a little more than connect a generative model to an amortizer. It does so through the help of a <code class="docutils literal notranslate"><span class="pre">configurator</span></code>. In our case the configurator was inferred from the type of amortizer provided, but for more involved models, you should define the configurator explicitly.</p>
<p>What does a configurator do? It takes the raw outputs of the generative models and turns them into something with which neural networks can work:</p>
<p><img alt="ef0889e4248f4de3a3b2f197b4ea5369" class="no-scaled-link" src="../_images/trainer_connection.png" style="width: 75%;" /></p>
<p>Let’s see how this actually works by accessing the default (inferred) configurator from the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> instance.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate some data again</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Keys of simulated dict: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Keys of simulated dict:  [&#39;prior_non_batchable_context&#39;, &#39;prior_batchable_context&#39;, &#39;prior_draws&#39;, &#39;sim_non_batchable_context&#39;, &#39;sim_batchable_context&#39;, &#39;sim_data&#39;]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conf_out</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">configurator</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Keys of configured dict: &#39;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">conf_out</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Keys of configured dict:  [&#39;parameters&#39;, &#39;summary_conditions&#39;, &#39;direct_conditions&#39;]
</pre></div></div>
</div>
<p>The default configurator for posterior inference differentiates between three types of model outputs: 1. <code class="docutils literal notranslate"><span class="pre">parameters</span></code> - these are the quantities for which we want posteriors. 2. <code class="docutils literal notranslate"><span class="pre">summary_conditions</span></code> - these are the quantities that go through the summary network (typically the raw data). 3. <code class="docutils literal notranslate"><span class="pre">direct_conditions</span></code> – these are concatenated with the outputs of the summary network and passed directly to the inference network.</p>
<p>In our case, <code class="docutils literal notranslate"><span class="pre">summary_conditions</span></code> simply correspond to the data, and <code class="docutils literal notranslate"><span class="pre">parameters</span></code> correspond to the prior draws, but you can imagine that more complex scenarios are possible. Let’s confirm the former claims.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;sim_data&#39;</span><span class="p">],</span> <span class="n">conf_out</span><span class="p">[</span><span class="s1">&#39;summary_conditions&#39;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="s1">&#39;prior_draws&#39;</span><span class="p">],</span> <span class="n">conf_out</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
True
True
</pre></div></div>
</div>
<p>Here, we are not using direct equality, since the configurator converts <code class="docutils literal notranslate"><span class="pre">float64</span></code> numbers to <code class="docutils literal notranslate"><span class="pre">float32</span></code> so as to use GPU memory more efficiently.</p>
</section>
<section id="Training-Phase">
<h1>Training Phase<a class="headerlink" href="#Training-Phase" title="Permalink to this heading"></a></h1>
<p>The following training modes are currently available:</p>
<ul class="simple">
<li><p>Online training - This training regime is optimal for fast generative models which can efficiently simulated data on-the-fly. In order for this training regime to be efficient, on-the-fly batch simulations should not take longer than 2-3 seconds. The networks never see the same simulations twice.</p></li>
<li><p>Experience replay - This training regime is also good for fast generative models which can efficiently simulated data on-the-fly. It will use a memory replay buffer, as utilized in reinforcement learning, so the network will eventually “experience” some simulations multiple times.</p></li>
<li><p>Round-based training - This training regime is optimal for slow, but still reasonably performant generative models. In order for this training regime to be efficient, on-the-fly batch simulations should not take longer than one 2-3 minutes.</p></li>
<li><p>Offline training - This training regime is optimal for very slow, external simulators, which take several minutes for a single simulation. It assumes that all training data has been already simulated and stored on disk.</p></li>
</ul>
<p>Usually, domain modelers have a pretty good understanding of how fast a simulation model runs. We can also quickly measure the time taken for a given number of simulations (<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>) directly inside the notebook.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Wall time: 92.3 ms
</pre></div></div>
</div>
<p>We are well below the recommended 2-3 seconds for online training, so that is what we will do. Online training has three mandatory parameters: <code class="docutils literal notranslate"><span class="pre">epochs</span></code>, <code class="docutils literal notranslate"><span class="pre">iterations_per_epoch</span></code>, and <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>. Thus, the total number of simulations that will be performed by a single call (run) will be <code class="docutils literal notranslate"><span class="pre">epochs</span></code> <span class="math notranslate nohighlight">\(\times\)</span> <code class="docutils literal notranslate"><span class="pre">iterations_per_epoch</span></code> <span class="math notranslate nohighlight">\(\times\)</span> <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>. Moreover, the networks will never experience the same simulation twice, since each batch will contain a new set of
simulations.</p>
<section id="Online-Training">
<h2>Online Training<a class="headerlink" href="#Online-Training" title="Permalink to this heading"></a></h2>
<p>Note how the average loss goes down, along with the learning rate (LR). The latter happens, because BayesFlow uses a cosine decay for the learning rate by default, unless a custom optimizer from <code class="docutils literal notranslate"><span class="pre">tensorflow.optimizers</span></code> is provided. Thus, the learning rate will decrease atuomatically from its default value of <span class="math notranslate nohighlight">\(0.0005\)</span> to <span class="math notranslate nohighlight">\(0\)</span> over the course of the training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train_online</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">iterations_per_epoch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "563962a07688438d8397bf245f93bc64", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "bb31acde0a6e4890ab38af9685a1cf36", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c745f09eb050468fb5309204a91b5ab4", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "9194cbea25f44e20b785bc2c1434e86d", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e1683b0182304ed38ba5919245b9e3ba", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "37021ca40a3543c999e5badb35accbb5", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "109819b16751447db938d60af28c1709", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cab09ff6d2394a85addd68639af62782", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a448f068282a4566be979962e28e3571", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "e8430691cb14401b9c5d10056d67a477", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Wall time: 3min 7s
</pre></div></div>
</div>
</section>
<section id="Inspecting-the-Loss">
<h2>Inspecting the Loss<a class="headerlink" href="#Inspecting-the-Loss" title="Permalink to this heading"></a></h2>
<p>We can inspect the evolution of the loss via a utility function <code class="docutils literal notranslate"><span class="pre">plot_losses</span></code>, for which we will import the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module from <code class="docutils literal notranslate"><span class="pre">BayesFlow</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">diag</span><span class="o">.</span><span class="n">plot_losses</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_61_0.png" src="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_61_0.png" />
</div>
</div>
</section>
<section id="Validating-Consistency">
<h2>Validating Consistency<a class="headerlink" href="#Validating-Consistency" title="Permalink to this heading"></a></h2>
<p>Validating the consistency of our model-amortizer coupling is an important step which should be performed before any real data are presented to the networks. In other words, the model should work in the ‘’small world’’, before going out in the world of real data. In addition to a smooth loss reduction curve, we can use three diagnostic utilities.</p>
</section>
<section id="Latent-Space-Plot">
<h2>Latent Space Plot<a class="headerlink" href="#Latent-Space-Plot" title="Permalink to this heading"></a></h2>
<p>Since our training objective prescribes a unit Gaussian to the latent variable <span class="math notranslate nohighlight">\(\boldsymbol{z}\)</span> (see: <a class="reference external" href="https://arxiv.org/abs/2003.06281">https://arxiv.org/abs/2003.06281</a>), we expect that, upon good convergence, the latent space will exhibit the prescribed structure. We can quickly inspect this structure by calling the <code class="docutils literal notranslate"><span class="pre">diagnose_latent2d</span></code> method of the trainer.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">diagnose_latent2d</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_64_0.png" src="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_64_0.png" />
</div>
</div>
<p>Where did the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> get the data to create these plots? During training, the trainer secretly kept a portion of the model outputs into a <code class="docutils literal notranslate"><span class="pre">SimulationMemory</span></code> structure, which is then used by the diagnostic functions. Note, that these functions are also available as standalone versions in the <code class="docutils literal notranslate"><span class="pre">diagnostics</span></code> module, but require a novel validation set of simulations.</p>
</section>
<section id="Simulation-Based-Calibration">
<h2>Simulation-Based Calibration<a class="headerlink" href="#Simulation-Based-Calibration" title="Permalink to this heading"></a></h2>
<p>By now a classic in Bayesian analysis. If you are not familiar with this procedure, you must read about it here: <a class="reference external" href="https://arxiv.org/abs/1804.06788">https://arxiv.org/abs/1804.06788</a></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">diagnose_sbc_histograms</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_67_0.png" src="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_67_0.png" />
</div>
</div>
</section>
<section id="Posterior-z-score">
<h2>Posterior z-score<a class="headerlink" href="#Posterior-z-score" title="Permalink to this heading"></a></h2>
<p>A quick and dirty way to gain an understanding of how good point estimates and uncertainty estimates capture the “true” parameters, assuming the generative model is well-specified.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate validation simulations (unseen by the network)</span>
<span class="n">n_sim_validation</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">val_data</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">configurator</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">n_sim_validation</span><span class="p">))</span>

<span class="c1"># Draw 500 posterior samples for each of the 100 simulated data sets</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">amortizer</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Note the shapes of our resulting array: <code class="docutils literal notranslate"><span class="pre">(100,</span> <span class="pre">500,</span> <span class="pre">4)</span></code>. The resulting array holds the 500 posterior draws (axis 1) for each of the 100 data sets (axis 0). The final axis (axis 2) represents the number of target parameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Shape of posterior samples array:&#39;</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Shape of posterior samples array: (100, 500, 4)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[40]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span> <span class="o">=</span> <span class="n">diag</span><span class="o">.</span><span class="n">plot_recovery</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">val_data</span><span class="p">[</span><span class="s1">&#39;parameters&#39;</span><span class="p">],</span> <span class="n">param_names</span><span class="o">=</span><span class="p">[</span><span class="sa">r</span><span class="s1">&#39;$\mu_1$&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\mu_2$&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\mu_3$&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\mu_4$&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_72_0.png" src="../_images/tutorial_notebooks_Intro_Amortized_Posterior_Estimation_72_0.png" />
</div>
</div>
</section>
</section>
<section id="Inference-Phase">
<h1>Inference Phase<a class="headerlink" href="#Inference-Phase" title="Permalink to this heading"></a></h1>
<p>Once the approximator has passed all consistency checks, we can now go ahead and apply it to real data! Since the data-generating parameters of real systems are per definition unobservable, we cannot use the same methods as below for ascertaining real-world validity of our inferences. Hence, as in any modeling scenario, we would need external validation and posterior predictive checks.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Stefan T. Radev.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>